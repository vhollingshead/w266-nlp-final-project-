{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CfVC2xguHGHN",
        "Kju1-uyCI88v",
        "VIK9rKpdbGtU",
        "uuL-vEchrx9l",
        "_8LVFUuB_-z6"
      ],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations & Support Functions"
      ],
      "metadata": {
        "id": "e7D1wWc4RScm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tpc_ZtP74n_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19063c32-dc9b-48e7-de27-ff1c196829e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip  # ensures that pip is current\n",
        "!git clone https://github.com/google-research/bleurt.git\n",
        "!pip install ./bleurt"
      ],
      "metadata": {
        "id": "1TYkzjz-4t13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b777069-86be-4a13-9dd4-fe3cbba6981f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Cloning into 'bleurt'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 134 (delta 0), reused 17 (delta 0), pack-reused 116\u001b[K\n",
            "Receiving objects: 100% (134/134), 31.28 MiB | 23.50 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "Processing ./bleurt\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.11.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (2.14.0)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.1.0)\n",
            "Collecting sentencepiece (from BLEURT==0.0.2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2023.3.post1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow->BLEURT==0.0.2) (3.2.2)\n",
            "Building wheels for collected packages: BLEURT\n",
            "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456765 sha256=d1a9b43e67585e0b9fe9d33fb639d07b35acbd670317b5ccd3d35f9e29157f07\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6cs73wd6/wheels/92/4f/fb/afa555fa27aa9e2c7958df797a62cc4e74f0f459cec9c4fa7c\n",
            "Successfully built BLEURT\n",
            "Installing collected packages: sentencepiece, BLEURT\n",
            "Successfully installed BLEURT-0.0.2 sentencepiece-0.1.99\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads the BLEURT-base checkpoint.\n",
        "!wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip .\n",
        "!unzip BLEURT-20.zip"
      ],
      "metadata": {
        "id": "UBUFtbiV9kZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs the scoring.\n",
        "!python -m bleurt.score_files \\\n",
        "  -candidate_file=bleurt/test_data/candidates \\\n",
        "  -reference_file=bleurt/test_data/references \\\n",
        "  -bleurt_checkpoint=BLEURT-20"
      ],
      "metadata": {
        "id": "Te0OjN7q4uUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() # If the GPU is enabled, it will give the following output '/device:GPU:0'\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "id": "KVAForGyZVKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import bleurt\n",
        "from bleurt import score as bleurt_score\n",
        "import json\n",
        "\n",
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai\n",
        "\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()\n",
        "\n",
        "#The OpenAI Key\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "kNcfvymv4xaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(file_path, my_string):\n",
        "  with open(file_path, 'w') as file:\n",
        "      for string in my_string:\n",
        "          file.write(string + '\\n')\n",
        "  print(f\"Data saved to {file_path}\")"
      ],
      "metadata": {
        "id": "_vuIqROpCBw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_file(file_path, text_to_append):\n",
        "  with open(file_path, 'a') as file:\n",
        "      file.write(text_to_append + '\\n')"
      ],
      "metadata": {
        "id": "1uO6hNPDa_1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batchify_list(input_list, batch_size):\n",
        "    \"\"\"Divide a list into batches of specified size.\"\"\"\n",
        "    return [input_list[i:i + batch_size] for i in range(0, len(input_list), batch_size)]"
      ],
      "metadata": {
        "id": "sGA6lhfSbQBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from bleurt import score\n",
        "\n",
        "def bleu_bleurt(predicted_labels=None, true_labels=None):\n",
        "    \"\"\"\n",
        "    This function calculates the BLEU and BLEURT scores of predicted\n",
        "    translations against the true labels.\n",
        "\n",
        "    Formats:\n",
        "        predicted_labels: list(list(str))\n",
        "        true_labels: list(str)\n",
        "    \"\"\"\n",
        "\n",
        "    scores_dict = {'bleu_score_avg': None,\n",
        "                   'bleurt_score_avg': None}\n",
        "\n",
        "    # flatten predicted_labels\n",
        "    predicted_labels = np.array(predicted_labels).flatten().tolist()\n",
        "\n",
        "    # scoring with bleu\n",
        "    scores_bleu = [bleu.sentence_bleu([str(predicted).split()], str(true).split()) for predicted, true in zip(predicted_labels, true_labels)]\n",
        "    scores_dict['bleu_score_avg'] = np.mean(scores_bleu)\n",
        "\n",
        "    checkpoint = \"/content/BLEURT-20\"\n",
        "    bleurt_scorer = bleurt_score.BleurtScorer(checkpoint)\n",
        "\n",
        "    # scoring with bleurt\n",
        "    scores_bleurt = bleurt_scorer.score(references=true_labels, candidates=predicted_labels,\n",
        "                                        batch_size=128)\n",
        "    scores_dict['bleurt_score_avg'] = np.mean(scores_bleurt)\n",
        "\n",
        "    return scores_dict"
      ],
      "metadata": {
        "id": "pmzPFT6xKL-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_gpt(ft_model, prompt, test_lines, test_labels, few_shot, file_path):\n",
        "  predicted_labels = []\n",
        "  error_indices = []\n",
        "  i = 0\n",
        "  message_2 = [\n",
        "          {\"role\": \"system\", \"content\": prompt},\n",
        "          {\"role\": \"user\", \"content\": 'English: The Cook Islands do not have any cities but are composed of 15 different islands.'},\n",
        "          {\"role\": \"system\", \"content\": 'Tagalog: Walang kahit among siyudad ang Cock Islands sublet kinabibilangan ng 15 iba-ibang pula.'},\n",
        "          {\"role\": \"user\", \"content\": 'English: The main ones are Rarotonga and Aitutaki.'},\n",
        "          {\"role\": \"system\", \"content\": 'Tagalog: Ang pinakamalaki sa mga ito ay ang Rarotonga at Aitutaki.'}]\n",
        "  message_1 = [\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": 'English: The Cook Islands do not have any cities but are composed of 15 different islands.'},\n",
        "        {\"role\": \"system\", \"content\": 'Tagalog: Walang kahit among siyudad ang Cock Islands sublet kinabibilangan ng 15 iba-ibang pula.'}]\n",
        "  message_0 = [\n",
        "        {\"role\": \"system\", \"content\": prompt}]\n",
        "\n",
        "  if few_shot == 2:\n",
        "    message = message_2\n",
        "  elif few_shot == 1:\n",
        "    message = message_1\n",
        "  else:\n",
        "    message = message_0\n",
        "\n",
        "  for batch in test_batch:\n",
        "    print(\"Start of New Batch\")\n",
        "    for item in batch:\n",
        "      try:\n",
        "        message.append({\"role\": \"user\", \"content\": item})\n",
        "        response = client.chat.completions.create(\n",
        "          model= ft_model,\n",
        "          messages=message\n",
        "        )\n",
        "        engtgl_translation = response.choices[0].message.content\n",
        "        predicted_labels.append(str(engtgl_translation))\n",
        "        update_file(file_path, engtgl_translation)\n",
        "      except Exception as e:\n",
        "        error_indices.append(i)\n",
        "        print(f\"Error at index {i}: {str(e)}\")\n",
        "      finally:\n",
        "        i += 1\n",
        "    print(str(i) + ' out of 402 completed')\n",
        "  test_labels_noerror = [label for index, label in enumerate(test_labels) if index not in error_indices]\n",
        "  scores_dict = bleu_bleurt(predicted_labels,test_labels_noerror)\n",
        "  return predicted_labels, scores_dict, error_indices"
      ],
      "metadata": {
        "id": "cCGF6z15N23v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Flores200 Train & Val Datasets"
      ],
      "metadata": {
        "id": "A9va2i5jbRl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load train, val, and test datasets\n",
        "train_path = '/content/drive/MyDrive/w266_project/FloRes200/train_eng_inputs.txt'\n",
        "val_path = '/content/drive/MyDrive/w266_project/FloRes200/val_eng_inputs.txt'\n",
        "test_path = '/content/drive/MyDrive/w266_project/FloRes200/test_eng_inputs.txt'\n",
        "\n",
        "train_label = '/content/drive/MyDrive/w266_project/FloRes200/train_tgl_labels.txt'\n",
        "val_label = '/content/drive/MyDrive/w266_project/FloRes200/val_tgl_labels.txt'\n",
        "test_label = '/content/drive/MyDrive/w266_project/FloRes200/test_tgl_labels.txt'\n",
        "\n",
        "with open(train_path, 'r') as file:\n",
        "    train_lines = [line.strip() for line in file]\n",
        "\n",
        "with open(val_path, 'r') as file:\n",
        "    val_lines = [line.strip() for line in file]\n",
        "\n",
        "with open(test_path, 'r') as file:\n",
        "    test_lines = [line.strip() for line in file]\n",
        "\n",
        "with open(train_label, 'r') as file:\n",
        "    train_labels = [line.strip() for line in file]\n",
        "\n",
        "with open(val_label, 'r') as file:\n",
        "    val_labels = [line.strip() for line in file]\n",
        "\n",
        "with open(test_label, 'r') as file:\n",
        "    test_labels = [line.strip() for line in file]"
      ],
      "metadata": {
        "id": "MXSPriAh5As2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train dataset size: {len(train_lines)}\")\n",
        "print()\n",
        "print(f\"Val dataset size: {len(val_lines)}\")\n",
        "print()\n",
        "print(f\"Test dataset size: {len(test_lines)}\")"
      ],
      "metadata": {
        "id": "kgVtIYoa5ENV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189f4fd1-6941-4416-e7ee-5db5627e5c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 1205\n",
            "\n",
            "Val dataset size: 402\n",
            "\n",
            "Test dataset size: 402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_lines[0])\n",
        "print(train_labels[0])"
      ],
      "metadata": {
        "id": "67vgDueK5GsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec07413-4421-4483-bf6a-06284ca4721d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scotturb Bus 403 travels regularly to Sintra, stopping at Cabo da Roca.\n",
            "Regular na bumibiyahe ang Scotturb Bus 403 patungong Sintra, tumitigil sa Cabo da Roca.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = batchify_list(test_lines, 25)\n",
        "print(len(test_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rp_z0ejnbWQ",
        "outputId": "f6723d8d-2c17-499f-fe09-8f2c086a691d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Compiled Test Dataset"
      ],
      "metadata": {
        "id": "CfVC2xguHGHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def print_json_structure(data, indent=0):\n",
        "    for key, value in data.items():\n",
        "        print('  ' * indent + str(key), end=': ')\n",
        "        if isinstance(value, dict):\n",
        "            print()\n",
        "            print_json_structure(value, indent + 1)\n",
        "        elif isinstance(value, list):\n",
        "            print(f'List of {len(value)} items')\n",
        "            if value and isinstance(value[0], dict):\n",
        "                print_json_structure(value[0], indent + 1)\n",
        "        else:\n",
        "            print(type(value).__name__)"
      ],
      "metadata": {
        "id": "QOkUm8ZyHKMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/w266_project/Final_Splits/corpora_splits.json'\n",
        "\n",
        "# Open and read the JSON file\n",
        "with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Print the structure of the JSON file\n",
        "print_json_structure(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO14tzWkHORg",
        "outputId": "30ec710e-6de4-4ff2-f18f-39ff85de9251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_eng_inputs: List of 41653 items\n",
            "val_eng_inputs: List of 4629 items\n",
            "test_eng_inputs: List of 1000 items\n",
            "train_tgl_labels: List of 41653 items\n",
            "val_tgl_labels: List of 4629 items\n",
            "test_tgl_labels: List of 1000 items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "native_speaker_test_lines = data['test_eng_inputs'][:5]\n",
        "native_speaker_test_labels = data['test_tgl_labels'][:5]\n",
        "\n",
        "print(f\"Test dataset size: {len(native_speaker_test_lines)}\")\n",
        "print(f\"Test label dataset size: {len(native_speaker_test_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70mIxyDOHv4p",
        "outputId": "91330735-f9d4-4805-dab2-1b65427d1205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset size: 5\n",
            "Test label dataset size: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(native_speaker_test_lines[0])\n",
        "print(native_speaker_test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pCVP20nJZiL",
        "outputId": "6dc2789b-1afe-43bf-b62b-2cf71c564a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A bottle fell onto the floor and shattered.\n",
            "Bote isang nahulog papunta sa sahig at shattered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Flores200 Test Dataset on Baseline Model"
      ],
      "metadata": {
        "id": "Kju1-uyCI88v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_predicted_engtgl_1.txt\"\n",
        "my_string = []\n",
        "save_file(file_path, my_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YD-xOdOJjVF",
        "outputId": "8af02ee2-0a2a-4582-bda5-8b39af16a82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/BASELINE_predicted_engtgl_1000.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = \"gpt-3.5-turbo\"\n",
        "prompt = \"Translate from English to Tagalog.\"\n",
        "few_shot = 0\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_predicted_engtgl_1.txt\"\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "predicted_labels, scores_dict, error_indices = prompt_gpt(ft_model, prompt, test_lines, test_labels, few_shot, file_path)\n",
        "print(\"Number of predicted_labels:\", len(predicted_labels))\n",
        "print()\n",
        "print(\"Number of error_indices:\", len(error_indices))\n",
        "print()\n",
        "total_lines = len(predicted_labels) + len(error_indices)\n",
        "print(\"Total predicted_labels and error_indices:\", total_lines)\n",
        "print()\n",
        "print(\"BLEU and BLEURT Scores:\", scores_dict)"
      ],
      "metadata": {
        "id": "6YL_ZIIZJCCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_predicted_engtgl_1.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    predicted_labels_load = [line.strip() for line in file]\n",
        "\n",
        "print(len(predicted_labels_load))\n",
        "print(len(test_lines))\n",
        "\n",
        "# print(len(predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNGLwvy0KBZ6",
        "outputId": "bd12eb16-1b17-4c0e-96da-0d7bbe06df8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "402\n",
            "402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User input:\", test_lines[-1])\n",
        "print(\"GPT 3.5 Turbo response:\", predicted_labels_load[-1])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"User input:\", test_lines[100])\n",
        "print(\"GPT 3.5 Turbo response:\", predicted_labels_load[100])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"User input:\", test_lines[0])\n",
        "print(\"GPT 3.5 Turbo response:\", predicted_labels_load[0])\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7t0PI98KD_e",
        "outputId": "b02ea6c1-4120-43fc-ba38-9ddead33b81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User input: First, the switch for the light fixture needs to be turned off or the cable disconnected.\n",
            "GPT 3.5 Turbo response: Unang-una, kailangan patayin ang switch ng ilaw o tanggalin ang kable.\n",
            "\n",
            "\n",
            "User input: On Wednesday, the United States' National Basketball Association (NBA) suspended its professional basketball season due to concerns regarding COVID-19.\n",
            "GPT 3.5 Turbo response: Sa Miyerkules, itinigil ng National Basketball Association (NBA) ng Estados Unidos ang kanilang propesyonal na basketball season dahil sa mga alalahanin ukol sa COVID-19.\n",
            "\n",
            "\n",
            "User input: In 1994, the ethnically Armenian Nagorno-Karabakh region of Azerbaijan waged war against the Azeris.\n",
            "GPT 3.5 Turbo response: Noong 1994, ang rehiyong etnikong Armenian ng Nagorno-Karabakh sa Azerbaijan ay nagsimulang mag-giyera laban sa mga Azeri.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dict_baseline = bleu_bleurt(predicted_labels_load,test_labels)\n",
        "print(scores_dict_baseline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTxZ8KYfd9Ud",
        "outputId": "af5b2d71-4f13-496b-bf48-182016ae328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu_score_avg': 0.21214525337448434, 'bleurt_score_avg': 0.5443149917754367}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune Model on Flores200 Train & Val Dataset"
      ],
      "metadata": {
        "id": "VIK9rKpdbGtU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMiZbdI7qZaV"
      },
      "outputs": [],
      "source": [
        "# Ensure you have the same number of input and label sentences\n",
        "# assert len(train_lines) == len(train_labels)\n",
        "\n",
        "base = 'Translate from English to Tagalog.'\n",
        "\n",
        "json_train = '/content/drive/MyDrive/w266_project/gpt-3.5_json_prompts/flores_eng_tgl_base_train.jsonl'\n",
        "json_val = '/content/drive/MyDrive/w266_project/gpt-3.5_json_prompts/flores_eng_tgl_base_val.jsonl'\n",
        "\n",
        "# Train JSON\n",
        "with open(json_train, 'w', encoding='utf-8') as file:\n",
        "    # Iterate over the paired sentences\n",
        "    for eng, tgl in zip(train_lines, train_labels):\n",
        "        # Create a dictionary for the current sentence pair\n",
        "        record_1 = {\"messages\": [{\"role\": \"system\", \"content\": base}, {\"role\": \"user\", \"content\": eng}, {\"role\": \"assistant\", \"content\": tgl}]}\n",
        "        # Convert the dictionary to a JSON string\n",
        "        json_record_1 = json.dumps(record_1, ensure_ascii=False)\n",
        "        # Write the JSON string to the file, followed by a newline\n",
        "        file.write(json_record_1 + '\\n')\n",
        "\n",
        "# Val JSON\n",
        "with open(json_val, 'w', encoding='utf-8') as file:\n",
        "    # Iterate over the paired sentences\n",
        "    for eng, tgl in zip(val_lines, val_labels):\n",
        "        # Create a dictionary for the current sentence pair\n",
        "        record_1 = {\"messages\": [{\"role\": \"system\", \"content\": base}, {\"role\": \"user\", \"content\": eng}, {\"role\": \"assistant\", \"content\": tgl}]}\n",
        "        # Convert the dictionary to a JSON string\n",
        "        json_record_1 = json.dumps(record_1, ensure_ascii=False)\n",
        "        # Write the JSON string to the file, followed by a newline\n",
        "        file.write(json_record_1 + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "training_file = client.files.create(\n",
        "  file=open(json_train, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "val_file = client.files.create(\n",
        "  file=open(json_val, \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "id": "U-pdP5wurDwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training File ID:', training_file.id)\n",
        "print('Val File ID:', val_file.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGqTcoDueXbn",
        "outputId": "8f2a538a-53f8-431f-c12b-17127647a153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training File ID: file-thNXtFb9YUSBXq6nOT7tlBo9\n",
            "Val File ID: file-wlnXi9Cg74YlVYDFo7E2p5Xg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file.id),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file.id)\n",
        ")"
      ],
      "metadata": {
        "id": "ko76OyM90kr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check status\n",
        "ft_jobs = client.fine_tuning.jobs.list(limit=1)\n",
        "print(ft_jobs)"
      ],
      "metadata": {
        "id": "-KgQfjnl1S6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f452fd3-e75b-41ea-bb2d-4f58d10c1945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-KoKE1YnUtyMDDVq4BuE4R7xG', created_at=1700644029, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-5TeNP380fjLiOrsiQuUc1fET', result_files=[], status='validating_files', trained_tokens=None, training_file='file-ZTxKpM1RKL7AvRq8RD2sXSSK', validation_file='file-i1EWq3dS1fUDHoYKSKXMqP0h')], object='list', has_more=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter-Tuning Iterations on Finetuned Model\n",
        "\n"
      ],
      "metadata": {
        "id": "uuL-vEchrx9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file.id),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file.id),\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":5,\n",
        "    \"batch_size\" :'auto',\n",
        "    \"learning_rate_multiplier\" : 'auto'}\n",
        ")\n",
        "# Val Loss: 0.4952\n",
        "# ftjob-P2I8hieu9ShHIU8ok5pJH4uK"
      ],
      "metadata": {
        "id": "v0oCfjoarw10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file.id),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file.id),\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 'auto',\n",
        "    \"batch_size\" : 16,\n",
        "    \"learning_rate_multiplier\" : 'auto'}\n",
        ")\n",
        "# Val Loss: 0.6515"
      ],
      "metadata": {
        "id": "uoZ4XLe5wUeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file.id),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file.id),\n",
        "  hyperparameters={\n",
        "    \"n_epochs\": 'auto',\n",
        "    \"batch_size\" : 'auto',\n",
        "    \"learning_rate_multiplier\" : 1.0}\n",
        ")\n",
        "# Val Loss: 0.7853"
      ],
      "metadata": {
        "id": "42NPChLRwehY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "training_file = 'file-thNXtFb9YUSBXq6nOT7tlBo9'\n",
        "val_file = 'file-wlnXi9Cg74YlVYDFo7E2p5Xg'\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file),\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":7,\n",
        "    \"batch_size\" :'auto',\n",
        "    \"learning_rate_multiplier\" : 'auto'}\n",
        ")\n",
        "\n",
        "# Val Loss: 0.9393"
      ],
      "metadata": {
        "id": "_DLzAqkpgH3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FAILED due to lack of credits\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "training_file = 'file-thNXtFb9YUSBXq6nOT7tlBo9'\n",
        "val_file = 'file-wlnXi9Cg74YlVYDFo7E2p5Xg'\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file),\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":7,\n",
        "    \"batch_size\" :16,\n",
        "    \"learning_rate_multiplier\" : 'auto'}\n",
        ")"
      ],
      "metadata": {
        "id": "1FDO3eisgXno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FAILED due to lack of credits\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "  training_file= str(training_file),\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  validation_file= str(val_file),\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":5,\n",
        "    \"batch_size\" : 16,\n",
        "    \"learning_rate_multiplier\" : 'auto'}\n",
        ")"
      ],
      "metadata": {
        "id": "ZbDUnCDMgHim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check status\n",
        "ft_jobs = client.fine_tuning.jobs.list(limit=1)\n",
        "print(ft_jobs)"
      ],
      "metadata": {
        "id": "CsrMQ52bsOb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply Test Dataset on Finetuned Model"
      ],
      "metadata": {
        "id": "_8LVFUuB_-z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_FINETUNE_predicted_engtgl_1000.txt\"\n",
        "my_string = []\n",
        "save_file(file_path, my_string)"
      ],
      "metadata": {
        "id": "BDazNyJ2bKbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee74d29-b7f6-48ec-8f90-c1bbe250803c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/BASELINE_FINETUNE_predicted_engtgl_1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch = batchify_list(test_lines, 25)"
      ],
      "metadata": {
        "id": "sjUhYxtBbhvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "prompt = \"Translate from English to Tagalog.\"\n",
        "few_shot = 0\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_FINETUNE_predicted_engtgl_1000.txt\"\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "predicted_labels_ft, scores_dict_ft, error_indices_ft = prompt_gpt(ft_model, prompt, test_lines, test_labels, few_shot, file_path)\n",
        "\n",
        "print(\"Number of predicted_labels:\", len(predicted_labels_ft))\n",
        "print()\n",
        "print(\"Number of error_indices:\", len(error_indices_ft))\n",
        "print()\n",
        "total_lines = len(predicted_labels_ft) + len(error_indices_ft)\n",
        "print(\"Total predicted_labels and error_indices:\", total_lines)\n",
        "print()\n",
        "print(\"BLEU and BLEURT Scores:\", scores_dict_ft)"
      ],
      "metadata": {
        "id": "DkTSel0x1WaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_FINETUNE_predicted_engtgl_1.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    predicted_labels_load_ft = [line.strip() for line in file]\n",
        "\n",
        "predicted_labels_load_ft = predicted_labels_load_ft[:-4]"
      ],
      "metadata": {
        "id": "ONSnTstQ8qI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the size of test_lines:', len(test_lines))\n",
        "print('This is the size of predicted_labels:', len(predicted_labels_load_ft))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB3tgx2EovDJ",
        "outputId": "15bebfa6-f6fe-40da-edd6-b2957c7b3b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the size of test_lines: 402\n",
            "This is the size of predicted_labels: 402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User input:\", test_lines[-1])\n",
        "print(\"FT GPT 3.5 response:\", predicted_labels_load_ft[-1])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"User input:\", test_lines[100])\n",
        "print(\"FT GPT 3.5 response:\", predicted_labels_load_ft[100])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"User input:\", test_lines[0])\n",
        "print(\"FT GPT 3.5 response:\", predicted_labels_load_ft[0])\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqMW8GR5hFoV",
        "outputId": "fc8f7f8a-1084-4787-af03-8724207ba266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User input: First, the switch for the light fixture needs to be turned off or the cable disconnected.\n",
            "FT GPT 3.5 response: Sa simula, ang parehong switch para sa mga ilaw sa kuwarto at sa labas nito ay kailangang naka-off o nakahiwalay ang kable.\n",
            "\n",
            "\n",
            "User input: On Wednesday, the United States' National Basketball Association (NBA) suspended its professional basketball season due to concerns regarding COVID-19.\n",
            "FT GPT 3.5 response: Ngayong Miyerkules, itinigil ng Pambansang Asosasyon ng Basketbol ng Estados Unidos (NBA) ang kanilang propesyonal na panahon ng basketbol dahil sa mga pangamba tungkol sa COVID-19.\n",
            "\n",
            "\n",
            "User input: In 1994, the ethnically Armenian Nagorno-Karabakh region of Azerbaijan waged war against the Azeris.\n",
            "FT GPT 3.5 response: Noong 1994, ang etnolinggwistikong rehiyon ng Nagorno-Karabakh ng Azebaijan ay sumalungat na sa giyeraan laban sa mga Azeri.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dict_ft = bleu_bleurt(predicted_labels_load_ft,test_labels)\n",
        "print(scores_dict_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGEEVavAhGsv",
        "outputId": "addb49f2-6eee-421a-a34e-15b07e591ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu_score_avg': 0.16440750059417866, 'bleurt_score_avg': 0.4320800552024177}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply Test Data on HP-Tuned FT Model"
      ],
      "metadata": {
        "id": "Ak4zFjn5BuFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_model = 'ft:gpt-3.5-turbo-0613:personal::8SKb9G6V'\n",
        "prompt = \"Translate from English to Tagalog.\"\n",
        "few_shot = 0\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/HP_FINETUNE_predicted_engtgl_1.txt\"\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "HP_predicted_labels = []\n",
        "i = 0\n",
        "for batch in test_batch:\n",
        "  for item in batch:\n",
        "    response = client.chat.completions.create(\n",
        "      model=hp_model,\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": item}\n",
        "      ]\n",
        "    )\n",
        "    engtgl_translation = response.choices[0].message.content\n",
        "    update_file(file_path, engtgl_translation)\n",
        "    HP_predicted_labels.append(str(engtgl_translation))\n",
        "    i += 1\n",
        "    print(str(i) + ' out of 402 completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf7uxGE_ByLm",
        "outputId": "6cfbba7a-4013-4cf9-c13d-a7377a2b862c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 402 completed\n",
            "2 out of 402 completed\n",
            "3 out of 402 completed\n",
            "4 out of 402 completed\n",
            "5 out of 402 completed\n",
            "6 out of 402 completed\n",
            "7 out of 402 completed\n",
            "8 out of 402 completed\n",
            "9 out of 402 completed\n",
            "10 out of 402 completed\n",
            "11 out of 402 completed\n",
            "12 out of 402 completed\n",
            "13 out of 402 completed\n",
            "14 out of 402 completed\n",
            "15 out of 402 completed\n",
            "16 out of 402 completed\n",
            "17 out of 402 completed\n",
            "18 out of 402 completed\n",
            "19 out of 402 completed\n",
            "20 out of 402 completed\n",
            "21 out of 402 completed\n",
            "22 out of 402 completed\n",
            "23 out of 402 completed\n",
            "24 out of 402 completed\n",
            "25 out of 402 completed\n",
            "26 out of 402 completed\n",
            "27 out of 402 completed\n",
            "28 out of 402 completed\n",
            "29 out of 402 completed\n",
            "30 out of 402 completed\n",
            "31 out of 402 completed\n",
            "32 out of 402 completed\n",
            "33 out of 402 completed\n",
            "34 out of 402 completed\n",
            "35 out of 402 completed\n",
            "36 out of 402 completed\n",
            "37 out of 402 completed\n",
            "38 out of 402 completed\n",
            "39 out of 402 completed\n",
            "40 out of 402 completed\n",
            "41 out of 402 completed\n",
            "42 out of 402 completed\n",
            "43 out of 402 completed\n",
            "44 out of 402 completed\n",
            "45 out of 402 completed\n",
            "46 out of 402 completed\n",
            "47 out of 402 completed\n",
            "48 out of 402 completed\n",
            "49 out of 402 completed\n",
            "50 out of 402 completed\n",
            "51 out of 402 completed\n",
            "52 out of 402 completed\n",
            "53 out of 402 completed\n",
            "54 out of 402 completed\n",
            "55 out of 402 completed\n",
            "56 out of 402 completed\n",
            "57 out of 402 completed\n",
            "58 out of 402 completed\n",
            "59 out of 402 completed\n",
            "60 out of 402 completed\n",
            "61 out of 402 completed\n",
            "62 out of 402 completed\n",
            "63 out of 402 completed\n",
            "64 out of 402 completed\n",
            "65 out of 402 completed\n",
            "66 out of 402 completed\n",
            "67 out of 402 completed\n",
            "68 out of 402 completed\n",
            "69 out of 402 completed\n",
            "70 out of 402 completed\n",
            "71 out of 402 completed\n",
            "72 out of 402 completed\n",
            "73 out of 402 completed\n",
            "74 out of 402 completed\n",
            "75 out of 402 completed\n",
            "76 out of 402 completed\n",
            "77 out of 402 completed\n",
            "78 out of 402 completed\n",
            "79 out of 402 completed\n",
            "80 out of 402 completed\n",
            "81 out of 402 completed\n",
            "82 out of 402 completed\n",
            "83 out of 402 completed\n",
            "84 out of 402 completed\n",
            "85 out of 402 completed\n",
            "86 out of 402 completed\n",
            "87 out of 402 completed\n",
            "88 out of 402 completed\n",
            "89 out of 402 completed\n",
            "90 out of 402 completed\n",
            "91 out of 402 completed\n",
            "92 out of 402 completed\n",
            "93 out of 402 completed\n",
            "94 out of 402 completed\n",
            "95 out of 402 completed\n",
            "96 out of 402 completed\n",
            "97 out of 402 completed\n",
            "98 out of 402 completed\n",
            "99 out of 402 completed\n",
            "100 out of 402 completed\n",
            "101 out of 402 completed\n",
            "102 out of 402 completed\n",
            "103 out of 402 completed\n",
            "104 out of 402 completed\n",
            "105 out of 402 completed\n",
            "106 out of 402 completed\n",
            "107 out of 402 completed\n",
            "108 out of 402 completed\n",
            "109 out of 402 completed\n",
            "110 out of 402 completed\n",
            "111 out of 402 completed\n",
            "112 out of 402 completed\n",
            "113 out of 402 completed\n",
            "114 out of 402 completed\n",
            "115 out of 402 completed\n",
            "116 out of 402 completed\n",
            "117 out of 402 completed\n",
            "118 out of 402 completed\n",
            "119 out of 402 completed\n",
            "120 out of 402 completed\n",
            "121 out of 402 completed\n",
            "122 out of 402 completed\n",
            "123 out of 402 completed\n",
            "124 out of 402 completed\n",
            "125 out of 402 completed\n",
            "126 out of 402 completed\n",
            "127 out of 402 completed\n",
            "128 out of 402 completed\n",
            "129 out of 402 completed\n",
            "130 out of 402 completed\n",
            "131 out of 402 completed\n",
            "132 out of 402 completed\n",
            "133 out of 402 completed\n",
            "134 out of 402 completed\n",
            "135 out of 402 completed\n",
            "136 out of 402 completed\n",
            "137 out of 402 completed\n",
            "138 out of 402 completed\n",
            "139 out of 402 completed\n",
            "140 out of 402 completed\n",
            "141 out of 402 completed\n",
            "142 out of 402 completed\n",
            "143 out of 402 completed\n",
            "144 out of 402 completed\n",
            "145 out of 402 completed\n",
            "146 out of 402 completed\n",
            "147 out of 402 completed\n",
            "148 out of 402 completed\n",
            "149 out of 402 completed\n",
            "150 out of 402 completed\n",
            "151 out of 402 completed\n",
            "152 out of 402 completed\n",
            "153 out of 402 completed\n",
            "154 out of 402 completed\n",
            "155 out of 402 completed\n",
            "156 out of 402 completed\n",
            "157 out of 402 completed\n",
            "158 out of 402 completed\n",
            "159 out of 402 completed\n",
            "160 out of 402 completed\n",
            "161 out of 402 completed\n",
            "162 out of 402 completed\n",
            "163 out of 402 completed\n",
            "164 out of 402 completed\n",
            "165 out of 402 completed\n",
            "166 out of 402 completed\n",
            "167 out of 402 completed\n",
            "168 out of 402 completed\n",
            "169 out of 402 completed\n",
            "170 out of 402 completed\n",
            "171 out of 402 completed\n",
            "172 out of 402 completed\n",
            "173 out of 402 completed\n",
            "174 out of 402 completed\n",
            "175 out of 402 completed\n",
            "176 out of 402 completed\n",
            "177 out of 402 completed\n",
            "178 out of 402 completed\n",
            "179 out of 402 completed\n",
            "180 out of 402 completed\n",
            "181 out of 402 completed\n",
            "182 out of 402 completed\n",
            "183 out of 402 completed\n",
            "184 out of 402 completed\n",
            "185 out of 402 completed\n",
            "186 out of 402 completed\n",
            "187 out of 402 completed\n",
            "188 out of 402 completed\n",
            "189 out of 402 completed\n",
            "190 out of 402 completed\n",
            "191 out of 402 completed\n",
            "192 out of 402 completed\n",
            "193 out of 402 completed\n",
            "194 out of 402 completed\n",
            "195 out of 402 completed\n",
            "196 out of 402 completed\n",
            "197 out of 402 completed\n",
            "198 out of 402 completed\n",
            "199 out of 402 completed\n",
            "200 out of 402 completed\n",
            "201 out of 402 completed\n",
            "202 out of 402 completed\n",
            "203 out of 402 completed\n",
            "204 out of 402 completed\n",
            "205 out of 402 completed\n",
            "206 out of 402 completed\n",
            "207 out of 402 completed\n",
            "208 out of 402 completed\n",
            "209 out of 402 completed\n",
            "210 out of 402 completed\n",
            "211 out of 402 completed\n",
            "212 out of 402 completed\n",
            "213 out of 402 completed\n",
            "214 out of 402 completed\n",
            "215 out of 402 completed\n",
            "216 out of 402 completed\n",
            "217 out of 402 completed\n",
            "218 out of 402 completed\n",
            "219 out of 402 completed\n",
            "220 out of 402 completed\n",
            "221 out of 402 completed\n",
            "222 out of 402 completed\n",
            "223 out of 402 completed\n",
            "224 out of 402 completed\n",
            "225 out of 402 completed\n",
            "226 out of 402 completed\n",
            "227 out of 402 completed\n",
            "228 out of 402 completed\n",
            "229 out of 402 completed\n",
            "230 out of 402 completed\n",
            "231 out of 402 completed\n",
            "232 out of 402 completed\n",
            "233 out of 402 completed\n",
            "234 out of 402 completed\n",
            "235 out of 402 completed\n",
            "236 out of 402 completed\n",
            "237 out of 402 completed\n",
            "238 out of 402 completed\n",
            "239 out of 402 completed\n",
            "240 out of 402 completed\n",
            "241 out of 402 completed\n",
            "242 out of 402 completed\n",
            "243 out of 402 completed\n",
            "244 out of 402 completed\n",
            "245 out of 402 completed\n",
            "246 out of 402 completed\n",
            "247 out of 402 completed\n",
            "248 out of 402 completed\n",
            "249 out of 402 completed\n",
            "250 out of 402 completed\n",
            "251 out of 402 completed\n",
            "252 out of 402 completed\n",
            "253 out of 402 completed\n",
            "254 out of 402 completed\n",
            "255 out of 402 completed\n",
            "256 out of 402 completed\n",
            "257 out of 402 completed\n",
            "258 out of 402 completed\n",
            "259 out of 402 completed\n",
            "260 out of 402 completed\n",
            "261 out of 402 completed\n",
            "262 out of 402 completed\n",
            "263 out of 402 completed\n",
            "264 out of 402 completed\n",
            "265 out of 402 completed\n",
            "266 out of 402 completed\n",
            "267 out of 402 completed\n",
            "268 out of 402 completed\n",
            "269 out of 402 completed\n",
            "270 out of 402 completed\n",
            "271 out of 402 completed\n",
            "272 out of 402 completed\n",
            "273 out of 402 completed\n",
            "274 out of 402 completed\n",
            "275 out of 402 completed\n",
            "276 out of 402 completed\n",
            "277 out of 402 completed\n",
            "278 out of 402 completed\n",
            "279 out of 402 completed\n",
            "280 out of 402 completed\n",
            "281 out of 402 completed\n",
            "282 out of 402 completed\n",
            "283 out of 402 completed\n",
            "284 out of 402 completed\n",
            "285 out of 402 completed\n",
            "286 out of 402 completed\n",
            "287 out of 402 completed\n",
            "288 out of 402 completed\n",
            "289 out of 402 completed\n",
            "290 out of 402 completed\n",
            "291 out of 402 completed\n",
            "292 out of 402 completed\n",
            "293 out of 402 completed\n",
            "294 out of 402 completed\n",
            "295 out of 402 completed\n",
            "296 out of 402 completed\n",
            "297 out of 402 completed\n",
            "298 out of 402 completed\n",
            "299 out of 402 completed\n",
            "300 out of 402 completed\n",
            "301 out of 402 completed\n",
            "302 out of 402 completed\n",
            "303 out of 402 completed\n",
            "304 out of 402 completed\n",
            "305 out of 402 completed\n",
            "306 out of 402 completed\n",
            "307 out of 402 completed\n",
            "308 out of 402 completed\n",
            "309 out of 402 completed\n",
            "310 out of 402 completed\n",
            "311 out of 402 completed\n",
            "312 out of 402 completed\n",
            "313 out of 402 completed\n",
            "314 out of 402 completed\n",
            "315 out of 402 completed\n",
            "316 out of 402 completed\n",
            "317 out of 402 completed\n",
            "318 out of 402 completed\n",
            "319 out of 402 completed\n",
            "320 out of 402 completed\n",
            "321 out of 402 completed\n",
            "322 out of 402 completed\n",
            "323 out of 402 completed\n",
            "324 out of 402 completed\n",
            "325 out of 402 completed\n",
            "326 out of 402 completed\n",
            "327 out of 402 completed\n",
            "328 out of 402 completed\n",
            "329 out of 402 completed\n",
            "330 out of 402 completed\n",
            "331 out of 402 completed\n",
            "332 out of 402 completed\n",
            "333 out of 402 completed\n",
            "334 out of 402 completed\n",
            "335 out of 402 completed\n",
            "336 out of 402 completed\n",
            "337 out of 402 completed\n",
            "338 out of 402 completed\n",
            "339 out of 402 completed\n",
            "340 out of 402 completed\n",
            "341 out of 402 completed\n",
            "342 out of 402 completed\n",
            "343 out of 402 completed\n",
            "344 out of 402 completed\n",
            "345 out of 402 completed\n",
            "346 out of 402 completed\n",
            "347 out of 402 completed\n",
            "348 out of 402 completed\n",
            "349 out of 402 completed\n",
            "350 out of 402 completed\n",
            "351 out of 402 completed\n",
            "352 out of 402 completed\n",
            "353 out of 402 completed\n",
            "354 out of 402 completed\n",
            "355 out of 402 completed\n",
            "356 out of 402 completed\n",
            "357 out of 402 completed\n",
            "358 out of 402 completed\n",
            "359 out of 402 completed\n",
            "360 out of 402 completed\n",
            "361 out of 402 completed\n",
            "362 out of 402 completed\n",
            "363 out of 402 completed\n",
            "364 out of 402 completed\n",
            "365 out of 402 completed\n",
            "366 out of 402 completed\n",
            "367 out of 402 completed\n",
            "368 out of 402 completed\n",
            "369 out of 402 completed\n",
            "370 out of 402 completed\n",
            "371 out of 402 completed\n",
            "372 out of 402 completed\n",
            "373 out of 402 completed\n",
            "374 out of 402 completed\n",
            "375 out of 402 completed\n",
            "376 out of 402 completed\n",
            "377 out of 402 completed\n",
            "378 out of 402 completed\n",
            "379 out of 402 completed\n",
            "380 out of 402 completed\n",
            "381 out of 402 completed\n",
            "382 out of 402 completed\n",
            "383 out of 402 completed\n",
            "384 out of 402 completed\n",
            "385 out of 402 completed\n",
            "386 out of 402 completed\n",
            "387 out of 402 completed\n",
            "388 out of 402 completed\n",
            "389 out of 402 completed\n",
            "390 out of 402 completed\n",
            "391 out of 402 completed\n",
            "392 out of 402 completed\n",
            "393 out of 402 completed\n",
            "394 out of 402 completed\n",
            "395 out of 402 completed\n",
            "396 out of 402 completed\n",
            "397 out of 402 completed\n",
            "398 out of 402 completed\n",
            "399 out of 402 completed\n",
            "400 out of 402 completed\n",
            "401 out of 402 completed\n",
            "402 out of 402 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/HP_FINETUNE_predicted_engtgl_1.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    predicted_labels_load_ft = [line.strip() for line in file]"
      ],
      "metadata": {
        "id": "tQEF5cYaB6FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the size of test_lines:', len(test_lines))\n",
        "print('This is the size of HP_predicted_labels:', len(HP_predicted_labels))\n",
        "print('This is the size of predicted_labels:', len(predicted_labels_load_ft))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_jGdX3CCAd_",
        "outputId": "1da3c40d-fd16-4178-c6e9-90ec6a8255fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the size of test_lines: 402\n",
            "This is the size of HP_predicted_labels: 402\n",
            "This is the size of predicted_labels: 404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User input:\", test_lines[-1])\n",
        "print(\"FT GPT 3.5 response:\", HP_predicted_labels[-1])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"User input:\", test_lines[100])\n",
        "print(\"FT GPT 3.5 response:\", HP_predicted_labels[100])\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"User input:\", test_lines[0])\n",
        "print(\"FT GPT 3.5 response:\", HP_predicted_labels[0])\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QidxJbr6CBal",
        "outputId": "827b3d19-eb2a-483b-bcbf-9fa9b2b0da0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User input: First, the switch for the light fixture needs to be turned off or the cable disconnected.\n",
            "FT GPT 3.5 response: Una sa lahat, ang switch para sa ilaw ay dapat i-off o ang kable ay alisin.\n",
            "\n",
            "\n",
            "User input: On Wednesday, the United States' National Basketball Association (NBA) suspended its professional basketball season due to concerns regarding COVID-19.\n",
            "FT GPT 3.5 response: Nitong Miyerkules, tinigil ng Pambansang Asosasyon ng Basketbol ng Estados Unidos (NBA) ang kanilang propesyonal na season ng basketbol dahil sa mga pangamba hinggil sa COVID-19.\n",
            "\n",
            "\n",
            "User input: In 1994, the ethnically Armenian Nagorno-Karabakh region of Azerbaijan waged war against the Azeris.\n",
            "FT GPT 3.5 response: Noong 1994, ang etnikong rehiyon ng Nagorno-Karabakh na Armenia sa Azerbaijan ay nanimulang makipagdigma sa mga Azeris.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HP Model Summary\n",
        "\n",
        "HP_scores_dict = bleu_bleurt(HP_predicted_labels,test_labels)\n",
        "print(HP_scores_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldKv34vUN8ZH",
        "outputId": "d11a1910-07fd-4863-b9e2-0ae1ba755a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu_score_avg': 0.1712545398867303, 'bleurt_score_avg': 0.43872055613357036}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Evaluation"
      ],
      "metadata": {
        "id": "iggA2w3GC9sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promptA = 'Translate from English to Tagalog.'\n",
        "promptB = 'You are a professional English-Tagalog translator. Translate from English to Tagalog.'\n",
        "promptC = 'You are a fluent English-Tagalog speaker. Translate from English to Tagalog.'\n",
        "promptD = 'Tagalog is an Austronesian language spoken in Luzon and neighboring islands and forming the basis of the standardized national language of the Philippines (Filipino). Its vocabulary has been much influenced by Spanish and English, and to some extent by Chinese, Sanskrit, Tamil, and Malay. Translate from English to Tagalog.'\n",
        "promptE = 'Tagalog is an Austronesian language spoken in Luzon and neighboring islands and forming the basis of the standardized national language of the Philippines (Filipino). Its vocabulary has been much influenced by Spanish and English, and to some extent by Chinese, Sanskrit, Tamil, and Malay. You are a professional English-Tagalog translator. Translate from English to Tagalog.'\n",
        "promptF = 'Tagalog is an Austronesian language spoken in Luzon and neighboring islands and forming the basis of the standardized national language of the Philippines (Filipino). Its vocabulary has been much influenced by Spanish and English, and to some extent by Chinese, Sanskrit, Tamil, and Malay. You are a fluent English-Tagalog speaker. Translate from English to Tagalog.'\n",
        "promptG_1shot = 'Tagalog is an Austronesian language spoken in Luzon and neighboring islands and forming the basis of the standardized national language of the Philippines (Filipino). Its vocabulary has been much influenced by Spanish and English, and to some extent by Chinese, Sanskrit, Tamil, and Malay. You are a professional English-Tagalog translator. We would like to translate English sentences to Tagalog. Here is an example of a translation. Make sure to translate correctly.'\n",
        "promptH_2shot = 'Tagalog is an Austronesian language spoken in Luzon and neighboring islands and forming the basis of the standardized national language of the Philippines (Filipino). Its vocabulary has been much influenced by Spanish and English, and to some extent by Chinese, Sanskrit, Tamil, and Malay. You are a fluent English-Tagalog speaker. We would like to translate English sentences to Tagalog. Here are some examples of translations. Make sure to translate correctly.'"
      ],
      "metadata": {
        "id": "w7HyHpm5DKUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt + Finetuning"
      ],
      "metadata": {
        "id": "dW-dVz9a2kqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_1_bl = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt1_BASELINE_predicted_engtgl.txt\"\n",
        "file_path_2_bl = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt2_BASELINE_predicted_engtgl.txt\"\n",
        "file_path_3_bl = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt3_BASELINE_predicted_engtgl.txt\"\n",
        "\n",
        "P1_predicted_labels = []\n",
        "P2_predicted_labels = []\n",
        "P3_predicted_labels = []\n",
        "\n",
        "save_file(file_path_1_bl, P1_predicted_labels)\n",
        "save_file(file_path_2_bl, P2_predicted_labels)\n",
        "save_file(file_path_3_bl, P3_predicted_labels)"
      ],
      "metadata": {
        "id": "bRIzbTt0cvK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1e173d-0a90-46c8-c879-c29e3913a114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/Prompt1_BASELINE_predicted_engtgl.txt\n",
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/Prompt2_BASELINE_predicted_engtgl.txt\n",
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/Prompt3_BASELINE_predicted_engtgl.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = promptC\n",
        "prompt_2 = promptD\n",
        "prompt_3 = promptH_2shot"
      ],
      "metadata": {
        "id": "XOeVxgq92msr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "# ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt1_BASELINE_predicted_engtgl.txt\"\n",
        "prompt = promptC\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "P1_predicted_labels = []\n",
        "i = 0\n",
        "for batch in test_batch:\n",
        "  for item in batch:\n",
        "    response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": item}\n",
        "      ]\n",
        "    )\n",
        "    engtgl_translation = response.choices[0].message.content\n",
        "    update_file(file_path, engtgl_translation)\n",
        "    P1_predicted_labels.append(str(engtgl_translation))\n",
        "    i += 1\n",
        "    print(str(i) + ' out of 402 completed')\n"
      ],
      "metadata": {
        "id": "cH6tesd4BeDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt1_BASELINE_predicted_engtgl.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    P1_predicted_labels_load = [line.strip() for line in file]\n",
        "\n",
        "print(\"Number of predicted_labels:\", len(P1_predicted_labels_load))\n",
        "print()\n",
        "print(\"Number of predicted_labels:\", len(P1_predicted_labels))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNQF-dro38_h",
        "outputId": "a0935a04-eb76-4c3f-8a2d-77e83ccff4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of predicted_labels: 403\n",
            "\n",
            "Number of predicted_labels: 402\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1 Summary\n",
        "\n",
        "scores_dict_ft = bleu_bleurt(P1_predicted_labels,test_labels)\n",
        "print(scores_dict_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTBS2ZOMi148",
        "outputId": "5af02f93-40c9-4790-e84c-18db8f011859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu_score_avg': 0.20798708301216756, 'bleurt_score_avg': 0.5378931139350234}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 2\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "# ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt2_BASELINE_predicted_engtgl.txt\"\n",
        "prompt = promptD\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "P2_predicted_labels = []\n",
        "i = 0\n",
        "for batch in test_batch:\n",
        "  for item in batch:\n",
        "    response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": item}\n",
        "      ]\n",
        "    )\n",
        "    engtgl_translation = response.choices[0].message.content\n",
        "    update_file(file_path, engtgl_translation)\n",
        "    P2_predicted_labels.append(str(engtgl_translation))\n",
        "    i += 1\n",
        "    print(str(i) + ' out of 402 completed')\n"
      ],
      "metadata": {
        "id": "77FIhbXcEZgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt2_BASELINE_predicted_engtgl.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    P2_predicted_labels_load = [line.strip() for line in file]\n",
        "\n",
        "print(\"Number of predicted_labels:\", len(P2_predicted_labels_load))\n",
        "print()\n",
        "print(\"Number of predicted_labels:\", len(P2_predicted_labels))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-vQo6UoZ7H3",
        "outputId": "f314911c-5955-474a-d9c6-0931a4d474a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of predicted_labels: 402\n",
            "\n",
            "Number of predicted_labels: 402\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 2 Summary\n",
        "\n",
        "P2_scores_dict = bleu_bleurt(P2_predicted_labels,test_labels)\n",
        "print(P2_scores_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeIC3zZ0aIQJ",
        "outputId": "950e9670-3c32-4e2e-a8bb-3c50fd5f3281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu_score_avg': 0.21840671367787864, 'bleurt_score_avg': 0.5481355164144466}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 3\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "# ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt3_BASELINE_predicted_engtgl.txt\"\n",
        "prompt = promptH_2shot\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "P3_predicted_labels = []\n",
        "i = 0\n",
        "for batch in test_batch:\n",
        "  for item in batch:\n",
        "    response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": 'English: The Cook Islands do not have any cities but are composed of 15 different islands.'},\n",
        "        {\"role\": \"system\", \"content\": 'Tagalog: Walang kahit among siyudad ang Cock Islands sublet kinabibilangan ng 15 iba-ibang pula.'},\n",
        "        {\"role\": \"user\", \"content\": 'English: The main ones are Rarotonga and Aitutaki.'},\n",
        "        {\"role\": \"system\", \"content\": 'Tagalog: Ang pinakamalaki sa mga ito ay ang Rarotonga at Aitutaki.'},\n",
        "        {\"role\": \"user\", \"content\": item}\n",
        "      ]\n",
        "    )\n",
        "    engtgl_translation = response.choices[0].message.content\n",
        "    update_file(file_path, engtgl_translation)\n",
        "    P3_predicted_labels.append(str(engtgl_translation))\n",
        "    i += 1\n",
        "    print(str(i) + ' out of 402 completed')\n"
      ],
      "metadata": {
        "id": "ZzFW-Wmwambg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt3_BASELINE_predicted_engtgl.txt\"\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    P3_predicted_labels_load = [line.strip() for line in file]\n",
        "\n",
        "print(\"Number of predicted_labels:\", len(P3_predicted_labels_load))\n",
        "print()\n",
        "print(\"Number of predicted_labels:\", len(P3_predicted_labels))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ES-eqh9bRcj",
        "outputId": "96378ec8-c28c-49d0-a66b-9e24c764aa65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of predicted_labels: 402\n",
            "\n",
            "Number of predicted_labels: 402\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 3 Summary\n",
        "\n",
        "P3_scores_dict = bleu_bleurt(P3_predicted_labels,test_labels)\n",
        "print(P3_scores_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJvKQFaXbajR",
        "outputId": "7a29fb4f-779b-43db-e20c-414f852c7baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu_score_avg': 0.21471100924878034, 'bleurt_score_avg': 0.5417923018595769}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gather Translations for Native Speaker Evaluation"
      ],
      "metadata": {
        "id": "jdzhuJve1Y8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASELINE_filepath_ns = \"/content/drive/MyDrive/w266_project/gpt_results/BASELINE_predicted_engtgl_ns.txt\"\n",
        "FINETUNE_filepath_ns = \"/content/drive/MyDrive/w266_project/gpt_results/FINETUNE_predicted_engtgl_ns.txt\"\n",
        "P1_filepath_ns = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt1_BASELINE_predicted_engtgl_ns.txt\"\n",
        "P2_filepath_ns = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt2_BASELINE_predicted_engtgl_ns.txt\"\n",
        "P3_filepath_ns = \"/content/drive/MyDrive/w266_project/gpt_results/Prompt3_BASELINE_predicted_engtgl_ns.txt\"\n",
        "\n",
        "P1_predicted_labels = []\n",
        "P2_predicted_labels = []\n",
        "P3_predicted_labels = []\n",
        "\n",
        "save_file(BASELINE_filepath_ns, P1_predicted_labels)\n",
        "save_file(FINETUNE_filepath_ns, P2_predicted_labels)\n",
        "save_file(P1_filepath_ns, P3_predicted_labels)\n",
        "save_file(P2_filepath_ns, P3_predicted_labels)\n",
        "save_file(P3_filepath_ns, P3_predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ1BrRCkxhSh",
        "outputId": "7cdfcebe-92c2-4357-8c66-e1f12c5fde0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/Prompt2_BASELINE_predicted_engtgl_ns.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "native_speaker_test_lines = [\"A bottle fell onto the floor and shattered.\",\n",
        "                             \"Look at me.\",\n",
        "                             \"Saying sorry for what happened, I don't think Hae Ra would want that.\",\n",
        "                             \"CAPULET Why, how now, kinsman! wherefore storm you so?\",\n",
        "                             \"And what of Irene Adler?\"]"
      ],
      "metadata": {
        "id": "RRqysqu9Qemq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in native_speaker_test_lines:\n",
        "  print(item)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLj0ovx23G_p",
        "outputId": "fb84e829-2f00-4535-b92e-26a041f1d8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A bottle fell onto the floor and shattered.\n",
            "\n",
            "Look at me.\n",
            "\n",
            "Saying sorry for what happened, I don't think Hae Ra would want that.\n",
            "\n",
            "CAPULET Why, how now, kinsman! wherefore storm you so?\n",
            "\n",
            "And what of Irene Adler?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline\n",
        "prompt_base = \"Translate from English to Tagalog.\"\n",
        "batch = native_speaker_test_lines\n",
        "file_path = BASELINE_filepath_ns\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "baseline_predicted_labels = []\n",
        "i = 0\n",
        "for item in batch:\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": prompt_base},\n",
        "      {\"role\": \"user\", \"content\": item}\n",
        "    ]\n",
        "  )\n",
        "  engtgl_translation = response.choices[0].message.content\n",
        "  update_file(file_path, engtgl_translation)\n",
        "  P1_predicted_labels.append(str(engtgl_translation))\n",
        "  i += 1\n",
        "  print(str(i) + ' out of 5 completed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XJM7VHO1WrF",
        "outputId": "7fee52e7-eb5c-464c-896e-3478ddd704c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 5 completed\n",
            "2 out of 5 completed\n",
            "3 out of 5 completed\n",
            "4 out of 5 completed\n",
            "5 out of 5 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune\n",
        "\n",
        "prompt_base = \"Translate from English to Tagalog.\"\n",
        "batch = native_speaker_test_lines\n",
        "file_path = FINETUNE_filepath_ns\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "baseline_predicted_labels = []\n",
        "i = 0\n",
        "for item in batch:\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"ft:gpt-3.5-turbo-0613:personal::8Nebv94z\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": prompt_base},\n",
        "      {\"role\": \"user\", \"content\": item}\n",
        "    ]\n",
        "  )\n",
        "  engtgl_translation = response.choices[0].message.content\n",
        "  update_file(file_path, engtgl_translation)\n",
        "  P1_predicted_labels.append(str(engtgl_translation))\n",
        "  i += 1\n",
        "  print(str(i) + ' out of 5 completed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wybjpi942Cko",
        "outputId": "abad7807-0861-4462-b234-8f896af81074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 5 completed\n",
            "2 out of 5 completed\n",
            "3 out of 5 completed\n",
            "4 out of 5 completed\n",
            "5 out of 5 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune + Hyperparameter Tuning\n",
        "\n",
        "hp_model = 'ft:gpt-3.5-turbo-0613:personal::8SKb9G6V'\n",
        "prompt = \"Translate from English to Tagalog.\"\n",
        "batch = native_speaker_test_lines\n",
        "few_shot = 0\n",
        "file_path = \"/content/drive/MyDrive/w266_project/gpt_results/HP_FINETUNE_predicted_engtgl_ns.txt\"\n",
        "\n",
        "HP_predicted_labels = []\n",
        "save_file(file_path, HP_predicted_labels)\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "i = 0\n",
        "for item in batch:\n",
        "  response = client.chat.completions.create(\n",
        "    model=hp_model,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": prompt},\n",
        "      {\"role\": \"user\", \"content\": item}\n",
        "    ]\n",
        "  )\n",
        "  engtgl_translation = response.choices[0].message.content\n",
        "  update_file(file_path, engtgl_translation)\n",
        "  HP_predicted_labels.append(str(engtgl_translation))\n",
        "  i += 1\n",
        "  print(str(i) + ' out of 5 completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb3hGDvsPCoH",
        "outputId": "ed617809-db77-453b-deb1-b2caf23115ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/w266_project/gpt_results/HP_FINETUNE_predicted_engtgl_ns.txt\n",
            "1 out of 5 completed\n",
            "2 out of 5 completed\n",
            "3 out of 5 completed\n",
            "4 out of 5 completed\n",
            "5 out of 5 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "# ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "\n",
        "file_path = P1_filepath_ns\n",
        "prompt = promptC\n",
        "batch = native_speaker_test_lines\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "P1_predicted_labels = []\n",
        "i = 0\n",
        "for item in batch:\n",
        "  response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": prompt},\n",
        "      {\"role\": \"user\", \"content\": item}\n",
        "    ]\n",
        "  )\n",
        "  engtgl_translation = response.choices[0].message.content\n",
        "  update_file(file_path, engtgl_translation)\n",
        "  P1_predicted_labels.append(str(engtgl_translation))\n",
        "  i += 1\n",
        "  print(str(i) + ' out of 5 completed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seV716sT2OMS",
        "outputId": "3e4a2882-b4da-4267-f334-bdcc7bba57e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 5 completed\n",
            "2 out of 5 completed\n",
            "3 out of 5 completed\n",
            "4 out of 5 completed\n",
            "5 out of 5 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 2\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "# ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "\n",
        "file_path = P2_filepath_ns\n",
        "prompt = promptD\n",
        "batch = native_speaker_test_lines\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "P2_predicted_labels = []\n",
        "i = 0\n",
        "for item in batch:\n",
        "  response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": prompt},\n",
        "      {\"role\": \"user\", \"content\": item}\n",
        "    ]\n",
        "  )\n",
        "  engtgl_translation = response.choices[0].message.content\n",
        "  update_file(file_path, engtgl_translation)\n",
        "  P2_predicted_labels.append(str(engtgl_translation))\n",
        "  i += 1\n",
        "  print(str(i) + ' out of 5 completed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTfQuPWJ2qk6",
        "outputId": "42ee4d69-952e-4d35-d053-2cd19170c0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 5 completed\n",
            "2 out of 5 completed\n",
            "3 out of 5 completed\n",
            "4 out of 5 completed\n",
            "5 out of 5 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 3\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "# ft_model = 'ft:gpt-3.5-turbo-0613:personal::8Nebv94z'\n",
        "\n",
        "file_path = P3_filepath_ns\n",
        "prompt = promptH_2shot\n",
        "batch = native_speaker_test_lines\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "P3_predicted_labels = []\n",
        "i = 0\n",
        "for item in batch:\n",
        "  response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": prompt},\n",
        "      {\"role\": \"user\", \"content\": 'English: The Cook Islands do not have any cities but are composed of 15 different islands.'},\n",
        "      {\"role\": \"system\", \"content\": 'Tagalog: Walang kahit among siyudad ang Cock Islands sublet kinabibilangan ng 15 iba-ibang pula.'},\n",
        "      {\"role\": \"user\", \"content\": 'English: The main ones are Rarotonga and Aitutaki.'},\n",
        "      {\"role\": \"system\", \"content\": 'Tagalog: Ang pinakamalaki sa mga ito ay ang Rarotonga at Aitutaki.'},\n",
        "      {\"role\": \"user\", \"content\": item}\n",
        "    ]\n",
        "  )\n",
        "  engtgl_translation = response.choices[0].message.content\n",
        "  update_file(file_path, engtgl_translation)\n",
        "  P3_predicted_labels.append(str(engtgl_translation))\n",
        "  i += 1\n",
        "  print(str(i) + ' out of 5 completed')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBoLFzwI2t9i",
        "outputId": "25f452b8-dbde-46c8-c669-28734caa07bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 5 completed\n",
            "2 out of 5 completed\n",
            "3 out of 5 completed\n",
            "4 out of 5 completed\n",
            "5 out of 5 completed\n"
          ]
        }
      ]
    }
  ]
}